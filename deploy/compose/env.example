# Host networking mode: external Docker networks not required

# API Keys / Credentials 
NGC_API_KEY=xxxx # Must have build.nvidia.com access to pull nvcr.io/nim images
HF_TOKEN=xxxx

# NIM Settings
# If using RTX 6000 to deploy both stacks to same node leave unchanged, 
# else switch this to the host ip for the machine running the NIM stack
NIM_HOST=localhost 
LOCAL_NIM_CACHE=~/.cache/nim
# LOCAL_UID=$(id -u)
# LOCAL_GID=$(id -g)

# VLM (Cosmos Reason1 NIM) Settings
VLM_IMAGE=nvcr.io/nim/nvidia/cosmos-reason1-7b:1.4.0
VLM_PORT=8001
VLM_ENDPOINT=$NIM_HOST:$VLM_PORT
VLM_GPU_ID=1
VLM_GPU_COUNT=1

# LLM (Nemotron) Settings
LLM_IMAGE=nvcr.io/nim/nvidia/nvidia-nemotron-nano-9b-v2:1
#LLM_IMAGE=nvcr.io/nim/nvidia/llama-3.3-nemotron-super-49b-v1.5:1 
LLM_PORT=8002
LLM_ENDPOINT=$NIM_HOST:$LLM_PORT
LLM_GPU_ID=2
LLM_GPU_COUNT=1

# Cosmos Transfer 2.5 Settings
# Github Repo based image
TRANSFER_GRADIO_IMAGE=cosmos-transfer2_5-gradio:v1.3.0
TRANSFER_GRADIO_PORT=8080
TRANSFER_ENDPOINT=http://$NIM_HOST:$TRANSFER_GRADIO_PORT
TRANSFER_GPU_ID=3
TRANSFER_GPU_COUNT=1
# Model to launch (compose defaults to 'edge' if unset)
TRANSFER_MODEL_NAME=edge
# Hugging Face cache directory (used for volume mount and HF_HOME env)
HF_HOME=~/.cache/huggingface

# Workbench settings
NOTEBOOK_IMAGE=smart-city-sdg-workbench:latest
CARLA_SERVER_IMAGE=carlasim/carla:0.9.16
CARLA_HOST=localhost
CARLA_PORT=2000
CARLA_SERVER_ENDPOINT=$CARLA_HOST:$CARLA_PORT
CARLA_STREAM_PORT_UDP=2001
CARLA_STREAM_PORT_TCP=2002
CARLA_GPU_ID=0
NOTEBOOK_PORT=8888
NOTEBOOK_WORKDIR=../../notebooks
